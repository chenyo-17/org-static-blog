#+title: Go patterns
#+date: <2024-06-25 21:25>
#+description: This a personal note for the [[https://www.youtube.com/watch?v=IdCbMO0Ey9I][Go lecture]].
#+filetags: go design-pattern study

This a personal note for the [[https://www.youtube.com/watch?v=IdCbMO0Ey9I][Russ Cox guest lecture]].

* Concurrency vs Parallelism
- Concurrency: write a program to handle lot of things at once
  - not necessarily faster
- Parallelism: the program itself can do a lot of computations at once

* Use goroutines for states

** Matching a regex
- return if a given string matches a regex: start with ~"~, contains arbitrary escape sequence and ends with ~"~
- unclear logic: store states in the data
  #+begin_src go -n
state := 0
for {
	c := read()
	switch state {
	case 0:
		// first char must be "
		if c != '"' {
			return false
		}
		state = 1 // match the next char
	case 1:
		// ending with " matches
		if c == '"' {
			return true
		}
		if c == '\\' {
			state = 2
		} else {
			// transition to state 1 to match next char
			state = 1
		}
	case 2:
		// read the char, discard it and
		state = 1
	}
}
  #+end_src
- clear logic: store states in the code
  #+begin_src go -n
// no variable to store state
if read() != '"' {
	return false
}
var c rune // c is a Unicode, alias to int32
for c != '"' {
	c = read()
	if c == '\\' {
		read()  // skip the next char
	}
}
return true
  #+end_src

** When the state variable cannot be avoided
- the function needs to return the state
  #+begin_src go -n
type quoter struct {
	state int
}

func (q *quoter) Init() {
	r.state = 0
}
// proess each char based on current state
func (q *quoter) Write(c rune) Status {
	switch q.state {
	case 0:
		if c != '"' {
			return BadInput
		}
		q.state = 1
	case 1:
		if c == '"' {
			return Success
		}
		if c == '\\' {
			q.state = 2
		} else {
			q.state = 1
		}
	case 2:
		q.state = 1
	}
	return NeedMoreInput
}
#+end_src
- use additional goroutines to hold states
  #+begin_src go -n
type quoter struct {
	char chan rune
	status chan Status
}
func (q *quoter) Init() {
	q.char = make(chan rune)
	q.status = make(chan Status)
	// need to make sure why and when the goroutine will exit
	go q.parse()
	// blocks until it receives an initial status from parse()
	// to ensure that parse() is ready, i.e., q.status = NeedMoreInput
	// before Write() is called
	<-q.status
}
// Write sends the next char to q.char, which will be receivecd by parse()
// the status is a public state accessible by the user
func (q *quoter) Write(r rune) Status {
	q.char <- c
	// wait for the result
	return <-q.status
}
func (q *quoteReader) parse() {
	if q.read() != '"' {
		q.status <- SyntaxError
		return
	}
	var c rune
	for c!= '"' {
		c = q.read()
		if c == '\\' {
			q.read()
		}
	}
	q.status <- Done
}
// a helper function used in parse() to return the next char in q.char
func (q *quoter) read() int {
	q.status <- NeedMoreInput
	return <- q.char
}
func main() {
	q := &quoter{}
	q.Init()

	input := `"Hello, \"World\""`
	for _, c := range input {
		status := q.Write(c)
	}
}
  #+end_src
- check goroutine blockage
  - ~Ctrl-\~ sends ~SIGQUIT~
  - use the HTTP server's ~/debug/pprof/goroutine~ if importing ~net/http~


* Pattern 1: publish/subscribe server
- the information goes one way: server -> client
- close a channel to signal no new values will be sent
- prefer ~defer~ when unlocking the mutex
  #+begin_src go -n
type Server struct {
	mu  sync.Mutex // protect sub
	sub map[chan<- Event]bool  // whether a channel should be closed
}
func (s *Server) Init() {
	s.sub = make(map[chan<- Event]bool)
}
// publish an event to all subscribed channel
func (s *Server) Publish(e Event) {
	s.mu.Lock()  // each method could be called by many clients
	defer s.mu.Unlock()
	// need mutex here since it needs to read s.sub state
	for c := range s.sub {
		// if a goroutine consumes the channel events too slow
		// then a new event publish has to wait
		// before it can send to the channel
		// can add channel buffer to mitigate this
		c <- e
	}
}
// a channel starts to subscribe
func (s *Server) Subscribe(c chan<- Event) {
	s.mu.Lock()
	defer s.mu.Unlock()
	if s.sub[c] {
		// the mutex wil also be unlocked with defer
		panic("pubsub: already subscribed") 	}
	s.sub[c] = true
}
// a channel cancels the subscription
func (s *Server) Cancel(c chan<- Event) {
	s.mu.Lock()
	defer s.mu.Unlock()
	if !s.sub[c] {
		panic("pubsub: not subscribed")
	}
	close(c)
	delete(s.sub, c)
}
  #+end_src

** Options for slow goroutines
- slow down event generation
- drop events if it cannot be sent, e.g., ~os/signal~, ~runtime/pprof~
- queue events, e.g., add a ~helper~ between the server and each client, which also separates the concerns
  #+begin_src go -n
func helper(in <-chan Event, out chan<- Event) {
	var q []Event
	// if the in is closed, flash out the pending events in q
	// and close out
	for in != nil || len(q) > 0 {
		// decide whether and what to send
		var sendOut chan<- Event
		var next Event
		if len(q) > 0 {
			sendOut = out
			next = q[0]
		}
		select {
		case e, ok := <-in: // never reaches here after in = nil
			// ok tells whether in is closed
			if !ok {
				in = nil
				break
			}
			q = append(q, e)
		case sendOut <- next: // if len(q) == 0, sendOut = nil
			q = q[1:]
		}
	}
	close(out)
}
  #+end_src
- convert mutexes into goroutines, not suitable for Raft where state transition is complex
 #+begin_src go -n
type Server struct {
	publish   chan Event
	subscribe chan subReq  // a channel to queue unhandled subscription
	cancel    chan subReq
}
type subReq struct {
	c  chan<- Event
	// a signal of whether an operation succeeds
	ok chan bool
}

func (s *Server) Init() {
	s.publish = make(chan Event)
	s.subscribe = make(chan subReq)
	s.cancel = make(chan subReq)
	go s.loop()
}
func (s *Server) Publish(e Event) {
	// no mutex is required here
	// as it does not read state
	s.publish <- e
}
func (s *Server) Subscribe(c chan<- Event) {
	r := subReq{c: c, ok: make(chan bool)}
	s.subscribe <- r
	if !<-r.ok {  // wait for loop() handle result
		panic("pubsub: already subscribed")
	}
}
func (s *Server) Cancel(c chan<- Event) {
	r := subReq{c: c, ok: make(chan bool)}
	s.cancel <- r
	if !<-r.ok {
		panic("pubusb: not subscribed")
	}
}
func (s *Server) loop() {
	// now sub is a local variable, no lock is needed
	// sub maps from a subscribed channel to a helper channel
	sub := make(map[chan<- Event]chan<- Event)
	for {
		select {
		case e := <-s.publish:
			for _, h := range sub {
				// the event is published to a helper channel
				h <- e
			}
		case r := <-s.subscribe:
			// the helper channel exists
			// meaning the subscriber has been handled before
			if sub[r.c] != nil {
				r.ok <- false
				break
			}
			h = make(chan Event)
			go helper(h, r.c)
			sub[r.c] = h
			r.ok <- true
		case c := <-s.cancel:
			if !sub[r.c] == nil{
				r.ok <- false
				break
			}
			// close the helper channel
			close(sub[r.c])
			delete(sub, r.c)
			r.ok <- true
		}
	}
}
 #+end_src


* Pattern 2: work scheduler
- \(M\) tasks assigned to \(N\) servers/workers, \( M >> N\).

  #+begin_src go -n
func Schedule(servers []string, numTask int,
	call func(srv string, task int)) {

	idle := make(chan string, len(servers))
	// initialize a channel of idle servers
	for _, srv := range servers {
		idle <- srv
	}

	for task := 0, task < numTask; task++ {
		// if using task in the for loop rather than a local task,
		// there is a race: the loop goes on before the goroutinue starts,
		// so that some tasks are skipped.
		task := task
		// if moving srv := <- idle inside goroutine
		// a lot of goroutines are created simoutaneously and hung
		// due to non-idle server
		// leaving it outside so that a goroutine is only created when
		// there is an idle server (but it slows down the main loop)
		srv := <-idle
		go func() {
			call(srv, task) // server does the task
			// serve finishes the task and becomes idle again
			idle <- srv
		}()
	}

	// determine when all tasks are done / all servers are idle
	// this is used to prevent early exit when all tasks have been assigned
	// but the last servers have not finished
	for i :=0; i < len(servers); i++ {
		<-idle
	}
}
  #+end_src

- Optimization for the above code: while the task loop creates goroutines \(M\) times, actually there are only at most \(N\) active goroutines at any time.
  - Better to spin off a goroutine for each server.
  - The number of servers can be dynamic.

 #+begin_src go -n
func Schedule(servers chan string, numTask int,
	call func(srv string, task int)) {

	work := make(chan int)  // a queue of all works yet to be done
	done := make(chan bool) // a queue of all done tasks
	exit := make(chan bool) // signal when should not pull new servers

	runTasks := func(srv string) {
		// keep polling until work is closed
		for task := range work {
			if call(srv, task) {
				done <- true
			} else {
				// repush the task if it failed
				work <- task
			}
		}
	}

	// use a goroutine to avoid hanging when
	// no server is available
	go func() {
		for _, srv := range servers {
			for {
				select {
				case src := <-servers:
					go runTasks(srv)
				case <-exit:
					return
				}
			}
		}
	}()

	// The following code has a deadlock!
	// In the runTasks, the server pushes to done channel when a task is done.
	// However, the done channel is only pulled when the main routine has
	// pushed all tasks and close the work channel.
	// Therefore any server hangs when trying push the second done work.
	// for taks := 0; task < numTask; task++ {
	// 	work <- task
	// }
	// // signal no more task so that servers know
	// // when to termiante
	// close(work)

	// // wait until all tasks are done
	// for i := 0; i < numTask; i++ {
	// 	<-done
	// }

	// fix 1: one can switch between work and donw channel
	i := 0
WorkLoop:
	for task := 0; task < numTask; task++ {
		for {
			select {
			case work <- task:
				continue WorkLoop
			case <-done:
				i++
			}
		}
	}

	// wait for the last assigned tasks to be done
	for ; i < numTask; i++ {
		<-done
	}

	// only close work channel in the end,
	// in case some tasks failed and need to be redo
	close(work)
	exit <- true // stop pulling new servers

	// fix 2: move the work assignment to a separate go routine
	// go func() {
	// 	for task := ; task < numTask; task++ {
	// 		work <- task
	// 	}
	// 	close(work)
	// }()

	// fix 3: increase buffer for the work channel
	// work := make(chan int, numTask)
}
 #+end_src


* Pattern 3: replicated service client
- A client replicates its requests to multiple servers, waits for the first reply and changes its preferred server.

 #+begin_src go
func (c *Client) Call(args Args) Reply {
	type result struct {
		serverID int
		reply Reply
	}

	const timeout = 1 * time.Second
	t := time.NewTimer(timeout)
	defer t.Stop()

	// a channel for all servers to send reply
	// so that even if the client has received a reply
	// other later replies don't hang
	done := make(chan result, len(c.servers))

	c.mu.Lock()
	prefer := c.prefer
	c.mu.Unlock()

	var r result
	for off := 0; off < len(c.servers); off++ {
		// start from the preferred server
		id := (prefer + off) % len(c.servers)
		go func() {
			done <- result{id, c.callOne(c.servers[id], arfs)}
		}()

		// now wait for either a done signal or a timeout
		// if it is done, don't send to other servers
		// otherwise, reset the timer and sends to the next server
		select {
		case r = <-done:
			goto Done  // use a goto if it makes code clear
		case <-t.C:
			// timeout
			t.Reset(timeout)
		}
	}

	r = <-done  // wait for the first reply even if it is a RPC timeout

Done:
	c.mu.Lock()
	c.prefer = r.serverID // update preference
	c.mu.Unlock()
	return r.reply
}

 #+end_src


* Pattern 4: Protocol multiplexer
- A multiplexer sits in front of a service and forward messages between multiple clients and the service, e.g., an RPC.

 #+begin_src go -n
type ProtocolMux interface {
	// A mux is binded to a specific service
	Init(Service)
	// A client uses this method to send message to the service
	// and wait for the service reply
	Call(Msg) Msg
}

// Methods that a service exposes to let a mux use
// Underlining messgae processing are in the implementation
// of the actual service struct
type Service interface {
	// A tag is a muxing identifier in the request or reply message,
	// e.g., which client channel to send the reply
	ReadTag(Msg) int64
	// Send a request message to the service
	// multiple sends cannot be called concurrently
	// probably due to only a single channel between
	// mux and the service (serialization)
	Send(Msg)
	// Waits and return the reply message,
	// multiple recvs cannot be called concurrently
	Recv() Msg
}
 #+end_src

- The mux maintains a channel to queue unsent requests and a channel to queue unsent replies.

  #+begin_src go -n
type Mux struct {
	srv Service
	// stores unsent requests
	send chan Msg
	mu sync.Mutex
	// maps channel tag to channel
	// whose replies have not been sent out
	pending map[int64]chan<- Msg
}

func (m *Mux) Init(srv Service) {
	m.srv = srv
	m.pending = make(map[int64]chan Msg)
	go m.sendLoop()
	go m.recvLoop()
}

// sending out queued requests
func (m *Mux) sendLoop {
	for args := range m.send {
		m.srv.Send(args)
	}
}

func (m *Mux) recvLoop() {
	for {
		reply := m.srv.Recv()
		tag := m.srv.ReadTag(reply)
		m.mu.Lock()
		// get the reply channel
		done := m.pending[tag]
		// clear the channel since the message loop
		// is complete
		delete(m.pending, tag)
		m.mu.Unlock()

		if done == nil {
			panic("unexpected reply")
		}
		done <- reply
	}

}

// Clients call this method concurrently
func (m *Mux) Call(args Msg) (reply Msg) {
	tag := m.srv.ReadTag(args)
	// to record which message should reply
	// to which client
	done := make(chan Msg, 1)
	m.mu.Lock()
	if m.pending[tag] != nil {
		m.mu.Unlock()
		panic("duplicate request")
	}
	m.pending[tag] = done
	m.mu.Unlock()
	m.send <- args
	return <-done // hang until a reply is received
}
  #+end_src
